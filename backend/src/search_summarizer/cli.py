import argparse
import json
import sys
import os
import time
import requests
from bs4 import BeautifulSoup
from ddgs import DDGS
from groq import Groq
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# ==============================================================================
# Utility Functions
# ==============================================================================

def mock_summarize(query, error_message="Chave da API Groq n√£o detectada."):
    return {
        "aviso": f"Resumo simulado para '{query}'. Motivo: {error_message}",
        "detalhes": [
            "A funcionalidade de busca est√° operando.",
            "Verifique os logs do servidor para mais detalhes sobre o erro."
        ],
    }

def search_duckduckgo(query, max_results=8, region='br-pt'):
    try:
        with DDGS() as ddgs:
            results = list(ddgs.text(query, max_results=max_results, region=region))
        return results
    except Exception as e:
        print(f"Erro na busca DuckDuckGo: {e}", file=sys.stderr)
        return []

def scrape_page(url, timeout=5):
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
        response = requests.get(url, headers=headers, timeout=timeout)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        for script in soup(["script", "style", "nav", "footer", "header"]):
            script.decompose()
            
        text = soup.get_text()
        lines = (line.strip() for line in text.splitlines())
        chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
        text = '\n'.join(chunk for chunk in chunks if chunk)
        
        return text[:5000]
    except Exception:
        return ""

def call_groq(api_key, prompt, temperature=0.5, max_retries=3, model=None, force_json=True):
    """Generic Groq API call with retry + exponential backoff + model fallback."""
    client = Groq(api_key=api_key)
    
    # Prioritizes model if provided, otherwise default list
    models = [model] if model else ["llama-3.3-70b-versatile", "llama-3.1-8b-instant"]
    # Ensure fallback models if the first one fails
    if "llama-3.1-8b-instant" not in models:
        models.append("llama-3.1-8b-instant")

    for model in models:
        for attempt in range(max_retries):
            try:
                completion_params = {
                    "messages": [{"role": "user", "content": prompt}],
                    "model": model,
                    "temperature": temperature,
                }
                
                if force_json:
                    completion_params["response_format"] = {"type": "json_object"}
                
                completion = client.chat.completions.create(**completion_params)
                
                if model != models[0]:
                    print(f"  ‚ö° Usando modelo fallback: {model}", file=sys.stderr)
                
                content = completion.choices[0].message.content
                
                # Return parsed JSON if force_json, otherwise raw text
                return json.loads(content) if force_json else content
                
            except Exception as e:
                error_msg = str(e)
                if "429" in error_msg and attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 3
                    print(f"  ‚è≥ Rate limit ({model}). Aguardando {wait_time}s... ({attempt+1}/{max_retries})", file=sys.stderr)
                    time.sleep(wait_time)
                    continue
                elif "429" in error_msg and model != models[-1]:
                    print(f"  üîÑ Rate limit esgotado em {model}. Tentando modelo menor...", file=sys.stderr)
                    break  # break inner loop, try next model
                raise

# ==============================================================================
# Simple Search Mode (original)
# ==============================================================================

def summarize_with_groq(text, query, api_key):
    if not api_key:
        return mock_summarize(query, "Chave da API n√£o fornecida.")

    try:
        prompt = f"""
        Voc√™ √© um assistente de pesquisa avan√ßado. Seu objetivo √© criar um resumo estruturado e abrangente sobre "{query}" com base no texto fornecido abaixo.
        
        Regras de Resposta:
        1. Retorne APENAS um JSON v√°lido. N√£o use blocos de c√≥digo markdown.
        2. A estrutura do JSON deve ser hier√°rquica e sem√¢ntica.
        3. Use chaves em Portugu√™s.
        4. O JSON deve conter uma vis√£o geral, principais pontos, detalhes t√©cnicos (se aplic√°vel), e controv√©rsias ou opini√µes diversas (se houver).
        5. Seja direto e informativo.
        
        Texto Base:
        {text[:25000]} 
        """
        return call_groq(api_key, prompt)
    except Exception as e:
        error_msg = str(e)
        print(f"Erro na API Groq: {error_msg}", file=sys.stderr)
        if "401" in error_msg:
            return mock_summarize(query, "Chave da API inv√°lida (401).")
        if "400" in error_msg:
            return mock_summarize(query, "Requisi√ß√£o inv√°lida (400).")
        if "429" in error_msg:
            return mock_summarize(query, "Muitas requisi√ß√µes (429). Aguarde.")
        return mock_summarize(query, f"Erro na API: {error_msg}")

def run_simple_search(args):
    """Original simple search mode."""
    results = search_duckduckgo(args.query, args.max_results, args.region)
    
    if not results:
        return {"structured": {"erro": "Nenhum resultado encontrado"}, "sources": []}

    aggregated_text = ""
    sources = []
    
    for i, result in enumerate(results):
        sources.append(result.get('href'))
        snippet = result.get('body', '')
        aggregated_text += f"Fonte {i+1} ({result.get('title')}): {snippet}\n"
        
        if i < args.max_pages and not args.no_groq:
            content = scrape_page(result.get('href'))
            if content:
                aggregated_text += f"Conte√∫do extra da Fonte {i+1}: {content}\n"
    
    groq_api_key = os.environ.get("GROQ_API_KEY")
    
    if args.no_groq:
        summary_data = {"aviso": "Resumo via Groq desativado."}
    else:
        summary_data = summarize_with_groq(aggregated_text, args.query, groq_api_key)

    return {"structured": summary_data, "sources": sources}

# ==============================================================================
# Business Intelligence Mode
# ==============================================================================

BUSINESS_CATEGORIES = [
    {
        "id": "mercado",
        "nome": "Panorama do Mercado",
        "icone": "üìä",
        "cor": "#10b981",
        "foco": "tamanho do mercado em R$, taxa de crescimento (CAGR), tend√™ncias de consumo, sazonalidade, oportunidades de nicho",
        "nao_falar": "N√ÉO repita o que o usu√°rio j√° disse sobre o pr√≥prio neg√≥cio. Foque em dados EXTERNOS que ele ainda n√£o sabe."
    },
    {
        "id": "concorrentes",
        "nome": "Mapa de Concorrentes",
        "icone": "üéØ",
        "cor": "#f59e0b",
        "foco": "nomes dos concorrentes diretos na regi√£o, diferenciais de cada um, pontos fracos explor√°veis, compara√ß√£o de servi√ßos",
        "nao_falar": "N√ÉO liste apenas nomes. Para CADA concorrente cite: o que ele faz bem, o que faz mal, e como o usu√°rio pode super√°-lo."
    },
    {
        "id": "publico_alvo",
        "nome": "Quem Compra de Voc√™",
        "icone": "üë•",
        "cor": "#8b5cf6",
        "foco": "nomes e perfis de EMPRESAS COMPRADORAS (n√£o fornecedoras) do produto, setores que mais consomem, crit√©rios que esses compradores usam para escolher fornecedor, onde encontr√°-los",
        "nao_falar": "N√ÉO busque empresas do mesmo ramo do usu√°rio. Busque empresas que COMPRAM o produto do usu√°rio (seus potenciais clientes)."
    },
    {
        "id": "como_vender",
        "nome": "Como Prospectar Clientes",
        "icone": "üí∞",
        "cor": "#ef4444",
        "foco": "t√©cnicas concretas de prospec√ß√£o para esse nicho, scripts de abordagem, canais que realmente funcionam para B2B industrial, como montar lista de leads",
        "nao_falar": "N√ÉO d√™ conselhos vagos como 'invista em marketing'. D√™ PASSOS CONCRETOS com ferramentas e canais espec√≠ficos."
    },
    {
        "id": "presenca_online",
        "nome": "Presen√ßa Online",
        "icone": "üì±",
        "cor": "#3b82f6",
        "foco": "palavras-chave que clientes desse nicho pesquisam no Google, exemplos de Google Ads funcionais, como usar LinkedIn para B2B industrial, tipo de conte√∫do que gera leads nesse setor",
        "nao_falar": "N√ÉO fale sobre tarifas de importa√ß√£o, feiras internacionais ou coisas n√£o relacionadas a marketing digital. Foque APENAS em a√ß√µes online."
    },
    {
        "id": "precificacao",
        "nome": "Pre√ßos e Margens",
        "icone": "üíé",
        "cor": "#ec4899",
        "foco": "faixa de pre√ßo B2B/industrial (N√ÉO varejo), margem de lucro t√≠pica do setor, modelos de contrato recorrente, como precificar para ser competitivo sem sacrificar margem",
        "nao_falar": "N√ÉO mostre pre√ßos de lojas como Kalunga ou Leroy Merlin (isso √© varejo). Foque em pre√ßos entre EMPRESAS (B2B)."
    },
]

def generate_business_queries(description, api_key):
    """Use Groq to generate targeted search queries for each business category."""
    categories_detail = ""
    for cat in BUSINESS_CATEGORIES:
        categories_detail += f'    "{cat["id"]}": {cat["foco"]} (CUIDADO: {cat["nao_falar"]})\n'
    
    prompt = f"""Voc√™ √© um especialista em pesquisa de mercado B2B brasileiro.

Gere UMA query de busca para cada categoria baseada no neg√≥cio descrito.

REGRAS PARA AS QUERIES:
- 5 a 10 palavras cada
- Use o NOME T√âCNICO do produto/servi√ßo (ex: "cartonagem" ou "papel√£o ondulado", n√£o "embalagem")
- Inclua cidade/estado quando relevante
- Cada query deve buscar ALGO DIFERENTE ‚Äî sem sobreposi√ß√£o entre categorias
- publico_alvo: busque quem COMPRA esse produto (os clientes potenciais), N√ÉO quem fabrica
- precificacao: busque tabelas de pre√ßo INDUSTRIAIS/B2B, n√£o de varejo
- presenca_online: busque palavras-chave que COMPRADORES pesquisam quando precisam do produto
- como_vender: busque t√©cnicas de prospec√ß√£o B2B para o setor INDUSTRIAL

Neg√≥cio:
"{description}"

Categorias:
{categories_detail}

JSON:
{{
    "queries": {{
        "mercado": "query",
        "concorrentes": "query",
        "publico_alvo": "query",
        "como_vender": "query",
        "presenca_online": "query",
        "precificacao": "query"
    }}
}}"""
    return call_groq(api_key, prompt, temperature=0.2)

def search_and_summarize_category(category, query, business_description, api_key, region, max_results=6, max_pages=2):
    """Search and summarize for a single business category."""
    print(f"  [{category['icone']}] Buscando: {query}", file=sys.stderr)
    
    results = search_duckduckgo(query, max_results=max_results, region=region)
    
    if not results:
        return {
            "id": category["id"],
            "nome": category["nome"],
            "icone": category["icone"],
            "cor": category["cor"],
            "query_usada": query,
            "resumo": {"info": "Nenhum resultado encontrado para esta categoria."},
            "fontes": []
        }
    
    aggregated_text = ""
    sources = []
    
    for i, result in enumerate(results):
        url = result.get('href', '')
        sources.append(url)
        snippet = result.get('body', '')
        title = result.get('title', '')
        aggregated_text += f"Fonte {i+1} ({title}): {snippet}\n"
        
        if i < max_pages:
            content = scrape_page(url)
            if content:
                aggregated_text += f"Conte√∫do completo Fonte {i+1}: {content}\n"
    
    # Small delay to avoid rate limits
    time.sleep(2)
    
    try:
        prompt = f"""Voc√™ √© um consultor s√™nior de neg√≥cios. Analise dados reais da internet e gere um relat√≥rio √öTIL.

O CLIENTE:
{business_description}

SEU FOCO NESTA SE√á√ÉO: {category['foco']}

REGRAS CR√çTICAS ‚Äî LEIA ANTES DE RESPONDER:
1. Retorne APENAS JSON v√°lido.
2. {category.get('nao_falar', '')}
3. N√ÉO REPITA o que o cliente j√° disse sobre o pr√≥prio neg√≥cio. Ele j√° sabe que faz consultoria t√©cnica, que atende B2B, etc. Traga informa√ß√µes NOVAS que ele n√£o tem.
4. Fale em SEGUNDA PESSOA: "Voc√™ pode...", "Seu mercado...", "Seus concorrentes...". Nunca diga "o cliente" ou "a empresa".
5. Cite nomes reais, valores em R$, percentuais ‚Äî dados CONCRETOS dos textos abaixo. 
6. Se um dado n√£o existir nos textos, simplesmente N√ÉO inclua esse campo. N√ÉO escreva "dado n√£o dispon√≠vel".
7. CNPJ (XX.XXX.XXX/XXXX-XX) N√ÉO √© faturamento. Ignore CNPJs.
8. Cada recomenda√ß√£o deve ser uma A√á√ÉO CONCRETA execut√°vel em 1-2 semanas, com nome de ferramenta/canal/empresa quando poss√≠vel.
9. N√ÉO repita recomenda√ß√µes que j√° foram dadas em outras se√ß√µes. Cada se√ß√£o deve trazer VALOR √öNICO.

ESTRUTURA DO JSON:
{{
    "visao_geral": "2-3 frases com a principal conclus√£o NOVA para o cliente, sem repetir o que ele j√° sabe",
    "pontos_chave": [
        "Fato descoberto nos dados com n√∫mero ou nome concreto",
        "(m√≠nimo 3, m√°ximo 5 ‚Äî s√≥ inclua se for informa√ß√£o NOVA e √öTIL)"
    ],
    "recomendacoes": [
        "A√ß√£o concreta: o qu√™ fazer + como + com qual ferramenta/canal (m√≠nimo 2, m√°ximo 4)"
    ],
    "dados_relevantes": {{
        "chave": "valor concreto encontrado nos dados (S√ì inclua se tiver valor real, NUNCA coloque 'dado n√£o dispon√≠vel')"
    }}
}}

DADOS DA INTERNET:
{aggregated_text[:18000]}"""
        
        resumo = call_groq(api_key, prompt, temperature=0.3)
    except Exception as e:
        print(f"  ‚ùå Erro ao resumir {category['nome']}: {e}", file=sys.stderr)
        resumo = {"erro": f"N√£o foi poss√≠vel gerar resumo: {str(e)[:200]}"}
    
    return {
        "id": category["id"],
        "nome": category["nome"],
        "icone": category["icone"],
        "cor": category["cor"],
        "query_usada": query,
        "resumo": resumo,
        "fontes": sources
    }

def run_business_analysis(args):
    """Run multi-category business intelligence analysis."""
    description = args.query
    api_key = os.environ.get("GROQ_API_KEY")
    
    if not api_key:
        return {
            "businessMode": True,
            "categories": [],
            "allSources": [],
            "erro": "Chave da API Groq n√£o configurada. Adicione GROQ_API_KEY no arquivo .env."
        }
    
    # Step 1: Generate search queries using AI
    print("üß† Gerando queries de busca inteligentes...", file=sys.stderr)
    try:
        query_result = generate_business_queries(description, api_key)
        queries = query_result.get("queries", {})
        print(f"  ‚úÖ Queries geradas: {json.dumps(queries, ensure_ascii=False)}", file=sys.stderr)
    except Exception as e:
        print(f"‚ùå Erro ao gerar queries: {e}", file=sys.stderr)
        return {
            "businessMode": True,
            "categories": [],
            "allSources": [],
            "erro": f"Erro ao gerar queries de busca: {str(e)[:200]}"
        }
    
    # Step 2: Search and summarize SEQUENTIALLY to avoid rate limits
    print("üîç Executando buscas e an√°lises por categoria...", file=sys.stderr)
    categories_result = []
    all_sources = []
    
    for cat in BUSINESS_CATEGORIES:
        q = queries.get(cat["id"], f"{cat['nome']} {description[:50]}")
        try:
            result = search_and_summarize_category(
                cat, q, description, api_key, args.region,
                max_results=6, max_pages=2
            )
            categories_result.append(result)
            all_sources.extend(result.get("fontes", []))
        except Exception as e:
            print(f"  ‚ùå Erro na categoria {cat['id']}: {e}", file=sys.stderr)
            categories_result.append({
                "id": cat["id"],
                "nome": cat["nome"],
                "icone": cat["icone"],
                "cor": cat["cor"],
                "query_usada": q,
                "resumo": {"erro": f"Falha ao processar: {str(e)[:150]}"},
                "fontes": []
            })
    
    unique_sources = list(dict.fromkeys(all_sources))
    
    print(f"‚úÖ An√°lise completa! {len(categories_result)} categorias, {len(unique_sources)} fontes.", file=sys.stderr)
    
    return {
        "businessMode": True,
        "descricao": description,
        "categories": categories_result,
        "allSources": unique_sources
    }

# ==============================================================================
# Main
# ==============================================================================

def main():
    parser = argparse.ArgumentParser(description="Search and Summarize CLI")
    parser.add_argument("query", help="Search query or business description")
    parser.add_argument("--max-results", type=int, default=8)
    parser.add_argument("--max-pages", type=int, default=3)
    parser.add_argument("--max-sentences", type=int, default=5)
    parser.add_argument("--region", type=str, default="br-pt")
    parser.add_argument("--business", action="store_true", help="Enable business intelligence mode")
    parser.add_argument("--list-sources", action="store_true")
    parser.add_argument("--no-groq", action="store_true")
    parser.add_argument("--verbose", action="store_true")

    args = parser.parse_args()

    try:
        sys.stdout.reconfigure(encoding='utf-8')
    except Exception:
        pass

    if args.business:
        output = run_business_analysis(args)
    else:
        output = run_simple_search(args)

    print("--- Resumo ---")
    print(json.dumps(output, indent=2, ensure_ascii=False))
    
    sources = output.get("sources", output.get("allSources", []))
    print("Fontes utilizadas:")
    for url in (sources or []):
        print(url)

if __name__ == "__main__":
    main()
